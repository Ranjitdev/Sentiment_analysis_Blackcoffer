{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af29f0d0",
   "metadata": {},
   "source": [
    "Blackcoffer is an enterprise software and analytics consulting firm based in India and the European Union (Malta). It is a data-driven, technology, and decision science firm focused exclusively on big data and analytics, data-driven dashboards, applications development, information management, and consulting of any kind, from any source, on a massive scale. We are a young and global consulting shop helping enterprises and entrepreneurs to solve big data and analytics, data-driven dashboards, applications development, and information management problems to minimize risk, explore opportunities for future growth, and increase profits more effectively. We provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth of global insights into big data, data-driven dashboards, application development, and information management for organizations through combining unique, specialist services, and high-level human expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce406c25",
   "metadata": {},
   "source": [
    "# Data Extraction and NLP\n",
    "### Test Assignment\n",
    "## Objective\n",
    "    The objective of this assignment is to extract textual data articles from the given URL and perform text analysis to compute variables that are explained below. \n",
    "    \n",
    "## Data Extraction\n",
    "    Input.xlsx\n",
    "    For each of the articles, given in the input.xlsx file, extract the article text and save the extracted article in a text file with URL_ID as its file name.\n",
    "    While extracting text, please make sure your program extracts only the article title and the article text. It should not extract the website header, footer, or anything other than the article text. \n",
    "\n",
    "* *NOTE: YOU MUST USE PYTHON PROGRAMMING TO EXTRACT DATA FROM THE URLs. YOU CAN USE BEATIFULSOUP, SELENIUM OR SCRAPY, OR ANY OTHER PYTHON LIBRARIES THAT YOU PREFER FOR DATA CRAWLING. \n",
    "\n",
    "## Data Analysis\n",
    "    For each of the extracted texts from the article, perform textual analysis and compute variables, given in the output structure excel file. You need to save the output in the exact order as given in the output structure file, “Output Data Structure.xlsx”\n",
    "\n",
    "* *NOTE: YOU MUST USE PYTHON PROGRAMMING FOR THE DATA ANALYSIS\n",
    "\n",
    "\n",
    "## Variables\n",
    "    Definition of each of the variables given in the “Text Analysis.docx” file.\n",
    "    POSITIVE SCORE\n",
    "    NEGATIVE SCORE\n",
    "    POLARITY SCORE\n",
    "    SUBJECTIVITY SCORE\n",
    "    AVG SENTENCE LENGTH\n",
    "    PERCENTAGE OF COMPLEX WORDS\n",
    "    FOG INDEX\n",
    "    AVG NUMBER OF WORDS PER SENTENCE\n",
    "    COMPLEX WORD COUNT\n",
    "    WORD COUNT\n",
    "    SYLLABLE PER WORD\n",
    "    PERSONAL PRONOUNS\n",
    "    AVG WORD LENGTH\n",
    "\n",
    "## Output Data Structure\n",
    "    Output Variables: \n",
    "    All input variables in “Input.xlsx”\n",
    "    POSITIVE SCORE\n",
    "    NEGATIVE SCORE\n",
    "    POLARITY SCORE\n",
    "    SUBJECTIVITY SCORE\n",
    "    AVG SENTENCE LENGTH\n",
    "    PERCENTAGE OF COMPLEX WORDS\n",
    "    FOG INDEX\n",
    "    AVG NUMBER OF WORDS PER SENTENCE\n",
    "    COMPLEX WORD COUNT\n",
    "    WORD COUNT\n",
    "    SYLLABLE PER WORD\n",
    "    PERSONAL PRONOUNS\n",
    "    AVG WORD LENGTH\n",
    "    Checkout output data structure spreadsheet for the format of your output, i.e. “Output Data Structure.xlsx”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a46843",
   "metadata": {},
   "source": [
    "## Sentimental Analysis\n",
    "    Sentimental analysis is the process of determining whether a piece of writing is positive, negative, or neutral. The below Algorithm is designed for use in Financial Texts. It consists of steps:\n",
    "\n",
    "## Cleaning using Stop Words Lists\n",
    "    The Stop Words Lists (found in the folder StopWords) are used to clean the text so that Sentiment Analysis can be performed by excluding the words found in Stop Words List. \n",
    "\n",
    "## Creating a dictionary of Positive and Negative words\n",
    "    The Master Dictionary (found in the folder MasterDictionary) is used for creating a dictionary of Positive and Negative words. We add only those words in the dictionary if they are not found in the Stop Words Lists. \n",
    "\n",
    "## Extracting Derived variables\n",
    "    We convert the text into a list of tokens using the nltk tokenize module and use these tokens to calculate the 4 variables described below:\n",
    "\n",
    "* Positive Score: This score is calculated by assigning the value of +1 for each word if found in the Positive Dictionary and then adding up all the values.\n",
    "* Negative Score: This score is calculated by assigning the value of -1 for each word if found in the Negative Dictionary and then adding up all the values. We multiply the score with -1 so that the score is a positive number.\n",
    "* Polarity Score: This is the score that determines if a given text is positive or negative in nature. It is calculated by using the formula: \n",
    "    *Polarity Score = (Positive Score – Negative Score)/ ((Positive Score + Negative Score) + 0.000001) Range is from -1 to +1\n",
    "* Subjectivity Score: This is the score that determines if a given text is objective or subjective. It is calculated by using the formula: \n",
    "    *Subjectivity Score = (Positive Score + Negative Score)/ ((Total Words after cleaning) + 0.000001) Range is from 0 to +1\n",
    "\n",
    "## Analysis of Readability\n",
    "    Analysis of Readability is calculated using the Gunning Fox index formula described below.\n",
    "    Average Sentence Length = the number of words / the number of sentences\n",
    "    Percentage of Complex words = the number of complex words / the number of words \n",
    "    Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n",
    "\n",
    "## Average Number of Words Per Sentence\n",
    "    The formula for calculating is:\n",
    "    Average Number of Words Per Sentence = the total number of words / the total number of sentences\n",
    "\n",
    "## Complex Word Count\n",
    "    Complex words are words in the text that contain more than two syllables.\n",
    "\n",
    "## Word Count\n",
    "    We count the total cleaned words present in the text by \n",
    "    removing the stop words (using stopwords class of nltk package).\n",
    "    removing any punctuations like ? ! , . from the word before counting.\n",
    "\n",
    "## Syllable Count Per Word\n",
    "    We count the number of Syllables in each word of the text by counting the vowels present in each word. We also handle some exceptions like words ending with \"es\",\"ed\" by not counting them as a syllable.\n",
    "\n",
    "## Personal Pronouns\n",
    "    To calculate Personal Pronouns mentioned in the text, we use regex to find the counts of the words - “I,” “we,” “my,” “ours,” and “us”. Special care is taken so that the country name US is not included in the list.\n",
    "\n",
    "## Average Word Length\n",
    "    Average Word Length is calculated by the formula:\n",
    "    Sum of the total number of characters in each word/Total number of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81fbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "import requests\n",
    "import os\n",
    "from docx import Document\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6027b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = r'https://docs.google.com/spreadsheets/d/1D7QkDHxUSKnQhR--q0BAwKMxQlUyoJTQ/edit?usp=drive_link'\n",
    "objective_file = r'https://docs.google.com/document/d/1wHMJDDvEKksgPRFajZXeycUcldC57lqr/edit?usp=drive_link'\n",
    "output_file = r'https://docs.google.com/spreadsheets/d/1kHcx9epaZKB96zRItudnrDi57cFEndFI/edit?usp=drive_link'\n",
    "text_analysis = r'https://docs.google.com/document/d/11FuBgszZwCSpVWekJ6rR5tBLjU--xfIC/edit?usp=drive_link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f534738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_docs(url, file_name):\n",
    "    gdown.download(url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1dab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://docs.google.com/spreadsheets/d/1D7QkDHxUSKnQhR--q0BAwKMxQlUyoJTQ/edit?usp=drive_link\n",
      "From (redirected): https://docs.google.com/spreadsheets/d/1D7QkDHxUSKnQhR--q0BAwKMxQlUyoJTQ/export?format=xlsx\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\input.xlsx\n",
      "14.6kB [00:00, 166kB/s]\n",
      "Downloading...\n",
      "From (uriginal): https://docs.google.com/document/d/1wHMJDDvEKksgPRFajZXeycUcldC57lqr/edit?usp=drive_link\n",
      "From (redirected): https://docs.google.com/document/d/1wHMJDDvEKksgPRFajZXeycUcldC57lqr/export?format=docx\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\objctive.docx\n",
      "12.5kB [00:00, 82.8kB/s]\n",
      "Downloading...\n",
      "From (uriginal): https://docs.google.com/spreadsheets/d/1kHcx9epaZKB96zRItudnrDi57cFEndFI/edit?usp=drive_link\n",
      "From (redirected): https://docs.google.com/spreadsheets/d/1kHcx9epaZKB96zRItudnrDi57cFEndFI/export?format=xlsx\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\output.xlsx\n",
      "15.9kB [00:00, ?B/s]\n",
      "Downloading...\n",
      "From (uriginal): https://docs.google.com/document/d/11FuBgszZwCSpVWekJ6rR5tBLjU--xfIC/edit?usp=drive_link\n",
      "From (redirected): https://docs.google.com/document/d/11FuBgszZwCSpVWekJ6rR5tBLjU--xfIC/export?format=docx\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\test_analysis.docx\n",
      "14.6kB [00:00, 633kB/s]\n"
     ]
    }
   ],
   "source": [
    "download_docs(input_file, 'input.xlsx')\n",
    "download_docs(objective_file, 'objctive.docx')\n",
    "download_docs(output_file, 'output.xlsx')\n",
    "download_docs(text_analysis, 'test_analysis.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00e7f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dic = r'https://drive.google.com/drive/folders/1YRcVlJO3ZaC78iTC6JcunfZl7Fz4AL8v?usp=drive_link'\n",
    "stopwords = r'https://drive.google.com/drive/folders/1rd7YdoX8tED9mujc0c-6evJU4y7LFc_R?usp=drive_link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32a4a3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1qqMwc_-ayS38HEOB97osO_nkIxRkbnvh negative-words.txt\n",
      "Processing file 1seAj8G42SmfgUUx8lqVDJofm4Tuh2TOT positive-words.txt\n",
      "Building directory structure completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder list completed\n",
      "Building directory structure\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qqMwc_-ayS38HEOB97osO_nkIxRkbnvh\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\master dictionary\\negative-words.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 44.8k/44.8k [00:01<00:00, 32.8kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1seAj8G42SmfgUUx8lqVDJofm4Tuh2TOT\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\master dictionary\\positive-words.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 19.1k/19.1k [00:00<00:00, 25.8kB/s]\n",
      "Download completed\n",
      "Retrieving folder list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1aWxyJI0d9MOk59OZ_unfBY5E-Nvg_ezW StopWords_Auditor.txt\n",
      "Processing file 1K-6MjPq5AQg4ICYY6PDfapB7JECUnryD StopWords_Currencies.txt\n",
      "Processing file 13LXnH6vaJhvY4s2ai_2oW2qwongU_iAI StopWords_DatesandNumbers.txt\n",
      "Processing file 1tTDfLXNPxNuUGZXHQkQhW6wPf4Xnivwr StopWords_Generic.txt\n",
      "Processing file 1PnZhcsfjBVxnzwa4N6MrLWf6Kuhhjpdk StopWords_GenericLong.txt\n",
      "Processing file 1RKxMOHzBdLrGuYb7MCJRTKKPwDG9Agbe StopWords_Geographic.txt\n",
      "Processing file 1mBOuggD8AVNFjr9sprLoD2_6mVWAgRGE StopWords_Names.txt\n",
      "Building directory structure completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder list completed\n",
      "Building directory structure\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1aWxyJI0d9MOk59OZ_unfBY5E-Nvg_ezW\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\stopwords\\StopWords_Auditor.txt\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 88.0/88.0 [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1K-6MjPq5AQg4ICYY6PDfapB7JECUnryD\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\stopwords\\StopWords_Currencies.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.76k/1.76k [00:00<00:00, 1.74MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=13LXnH6vaJhvY4s2ai_2oW2qwongU_iAI\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\stopwords\\StopWords_DatesandNumbers.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 832/832 [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1tTDfLXNPxNuUGZXHQkQhW6wPf4Xnivwr\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\stopwords\\StopWords_Generic.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 722/722 [00:00<?, ?B/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1PnZhcsfjBVxnzwa4N6MrLWf6Kuhhjpdk\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\stopwords\\StopWords_GenericLong.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.16k/4.16k [00:00<00:00, 2.09MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1RKxMOHzBdLrGuYb7MCJRTKKPwDG9Agbe\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\stopwords\\StopWords_Geographic.txt\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.82k/1.82k [00:00<00:00, 1.82MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mBOuggD8AVNFjr9sprLoD2_6mVWAgRGE\n",
      "To: C:\\Users\\PythonFiles\\PYcharm\\Sentiment_analysis_Blackcoffer\\notebook\\stopwords\\StopWords_Names.txt\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 107k/107k [00:00<00:00, 320kB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stopwords\\\\StopWords_Auditor.txt',\n",
       " 'stopwords\\\\StopWords_Currencies.txt',\n",
       " 'stopwords\\\\StopWords_DatesandNumbers.txt',\n",
       " 'stopwords\\\\StopWords_Generic.txt',\n",
       " 'stopwords\\\\StopWords_GenericLong.txt',\n",
       " 'stopwords\\\\StopWords_Geographic.txt',\n",
       " 'stopwords\\\\StopWords_Names.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdown.download_folder(master_dic, output='master dictionary')\n",
    "gdown.download_folder(stopwords, output='stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5ce595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = pd.read_excel('input.xlsx')\n",
    "input_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17788f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...             NaN   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...             NaN   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...             NaN   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...             NaN   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...             NaN   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0             NaN             NaN                 NaN                  NaN   \n",
       "1             NaN             NaN                 NaN                  NaN   \n",
       "2             NaN             NaN                 NaN                  NaN   \n",
       "3             NaN             NaN                 NaN                  NaN   \n",
       "4             NaN             NaN                 NaN                  NaN   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                          NaN        NaN                               NaN   \n",
       "1                          NaN        NaN                               NaN   \n",
       "2                          NaN        NaN                               NaN   \n",
       "3                          NaN        NaN                               NaN   \n",
       "4                          NaN        NaN                               NaN   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 NaN         NaN                NaN                NaN   \n",
       "1                 NaN         NaN                NaN                NaN   \n",
       "2                 NaN         NaN                NaN                NaN   \n",
       "3                 NaN         NaN                NaN                NaN   \n",
       "4                 NaN         NaN                NaN                NaN   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = pd.read_excel('output.xlsx')\n",
    "output_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a99d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17bc45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
